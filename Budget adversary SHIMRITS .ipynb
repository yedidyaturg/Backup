{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baeab84-3044-4534-97e7-a3fa7e791288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a800c52b-56cc-4df7-ac76-b7b9961d5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "\n",
    "\n",
    "def solve_SHIMRITS_adversary(\n",
    "    bar_p,\n",
    "    hat_p,\n",
    "    edges,\n",
    "    source,\n",
    "    sink,\n",
    "    Gamma,\n",
    "    gurobi_output=False,\n",
    "):\n",
    "    n = len(bar_p)\n",
    "\n",
    "    nodes = set()\n",
    "    for i, j in edges:\n",
    "        nodes.add(i)\n",
    "        nodes.add(j)\n",
    "    V = sorted(nodes)\n",
    "    \n",
    "    #Create Pi group\n",
    "    Pi = {0.0}\n",
    "    for i in range(n):\n",
    "        if hat_p[i] > 0:\n",
    "            Pi.add(float(hat_p[i]))\n",
    "    Pi = sorted(Pi)\n",
    "    \n",
    "    #The flow variables\n",
    "    out_arcs = {i: [] for i in V}\n",
    "    in_arcs = {i: [] for i in V}\n",
    "    for (i, j) in edges:\n",
    "        out_arcs[i].append((i, j))\n",
    "        in_arcs[j].append((i, j))\n",
    "\n",
    "    model = gp.Model(\"adv_compact\")\n",
    "    if not gurobi_output:\n",
    "        model.Params.OutputFlag = 0\n",
    "\n",
    "    phi = model.addVars(edges, lb=0, ub=1, name=\"phi\")\n",
    "    alpha = model.addVars(range(n), vtype=GRB.BINARY, name=\"alpha\")\n",
    "    t = model.addVar(lb=-GRB.INFINITY, name=\"t\")\n",
    "\n",
    "    model.update()\n",
    "\n",
    "\n",
    "    \n",
    "    for i in V:\n",
    "        if i == source:\n",
    "            model.addConstr(gp.quicksum(phi[e] for e in out_arcs[i]) == 1)\n",
    "        elif i == sink:\n",
    "            model.addConstr(gp.quicksum(phi[e] for e in in_arcs[i]) == 1)\n",
    "        else:\n",
    "            model.addConstr(\n",
    "                gp.quicksum(phi[e] for e in out_arcs[i]) -\n",
    "                gp.quicksum(phi[e] for e in in_arcs[i])\n",
    "                == 0\n",
    "            )\n",
    "\n",
    "    for i in range(n):\n",
    "        model.addConstr(\n",
    "            alpha[i] == gp.quicksum(phi[e] for e in out_arcs.get(i, [])),\n",
    "            name=f\"alpha_def_{i}\",\n",
    "        )\n",
    "\n",
    "    for pi in Pi:\n",
    "        expr = pi * Gamma\n",
    "        for i in range(n):\n",
    "            expr += max(hat_p[i] - pi, 0.0) * alpha[i]\n",
    "        model.addConstr(t <= expr, name=f\"pi_constraint_{pi}\")\n",
    "\n",
    "    obj = t + gp.quicksum(alpha[i] * bar_p[i] for i in range(n))\n",
    "    model.setObjective(obj, GRB.MAXIMIZE)\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status != GRB.OPTIMAL:\n",
    "        return dict(\n",
    "            best_value=None,\n",
    "            best_pi=None,\n",
    "            path_arcs=None,\n",
    "            phi=None,\n",
    "            alpha=None,\n",
    "        )\n",
    "\n",
    "    phi_sol = {e: phi[e].X for e in edges}\n",
    "    alpha_sol = [alpha[i].X for i in range(n)]\n",
    "    best_value = model.ObjVal\n",
    "\n",
    "    path_arcs = []\n",
    "    current = source\n",
    "    visited = set()\n",
    "    while current != sink and current not in visited:\n",
    "        visited.add(current)\n",
    "        nxt_arc = None\n",
    "        for e in out_arcs[current]:\n",
    "            if phi_sol.get(e, 0) > 0.5:\n",
    "                nxt_arc = e\n",
    "                break\n",
    "        if nxt_arc is None:\n",
    "            break\n",
    "        path_arcs.append(nxt_arc)\n",
    "        current = nxt_arc[1]\n",
    "\n",
    "    # compute minimizer pi after solving\n",
    "    t_star = t.X\n",
    "    best_pi = None\n",
    "    best_f_pi = float(\"inf\")\n",
    "    for pi in Pi:\n",
    "        f_pi = pi * Gamma\n",
    "        for i in range(n):\n",
    "            f_pi += max(hat_p[i] - pi, 0.0) * alpha_sol[i]\n",
    "        if f_pi < best_f_pi + 1e-6:\n",
    "            best_f_pi = f_pi\n",
    "            best_pi = pi\n",
    "\n",
    "    return dict(\n",
    "        best_value=best_value,\n",
    "        best_pi=best_pi,\n",
    "        path_arcs=path_arcs,\n",
    "        phi=phi_sol,\n",
    "        alpha=alpha_sol,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f90f72-67a0-48f8-bda3-93fc0597b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_adversary_bruni(\n",
    "    bar_p,\n",
    "    hat_p,\n",
    "    edges,\n",
    "    source,\n",
    "    sink,\n",
    "    Gamma,\n",
    "    gurobi_output=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Bruni-style adversarial subproblem formulation (Section 4.2):\n",
    "\n",
    "        max sum_(i,j) bar_p[i] * alpha_ij + hat_p[i] * w_ij\n",
    "\n",
    "    s.t. alpha defines a path from source to sink,\n",
    "         w_ij <= xi_i,\n",
    "         w_ij <= alpha_ij,\n",
    "         sum_i xi_i <= Gamma,\n",
    "         alpha_ij in {0,1},\n",
    "         0 <= xi_i <= 1, w_ij >= 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bar_p : list[float]\n",
    "        Nominal durations bar_p[i] for each activity node i.\n",
    "    hat_p : list[float]\n",
    "        Deviations hat_p[i] for each activity node i.\n",
    "    edges : list[tuple[int, int]]\n",
    "        List of directed arcs (i, j) in the extended project network.\n",
    "    source : int\n",
    "        Index of the source node.\n",
    "    sink : int\n",
    "        Index of the sink node.\n",
    "    Gamma : float or int\n",
    "        Budget parameter.\n",
    "    gurobi_output : bool, optional\n",
    "        If True, Gurobi's output flag is enabled.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "          \"value\": float,\n",
    "          \"path_arcs\": list[(i, j)],\n",
    "          \"alpha\": dict[(i,j)] -> float,\n",
    "          \"xi\": dict[i] -> float,\n",
    "          \"w\": dict[(i,j)] -> float\n",
    "        }\n",
    "    \"\"\"\n",
    "    n = len(bar_p)\n",
    "    nodes, out_arcs, in_arcs = _build_graph(edges)\n",
    "\n",
    "    model = gp.Model(\"adversary_bruni\")\n",
    "    model.Params.OutputFlag = 1 if gurobi_output else 0\n",
    "\n",
    "    # Binary path variables alpha_ij\n",
    "    alpha = {   \n",
    "        (i, j): model.addVar(vtype=GRB.BINARY, name=f\"alpha_{i}_{j}\")\n",
    "        for (i, j) in edges\n",
    "    }\n",
    "\n",
    "    # Continuous w_ij >= 0\n",
    "    w = {\n",
    "        (i, j): model.addVar(lb=0.0, vtype=GRB.CONTINUOUS, name=f\"w_{i}_{j}\")\n",
    "        for (i, j) in edges\n",
    "    }\n",
    "\n",
    "    # Activity delay variables xi_i in [0, 1]\n",
    "    xi = {\n",
    "        i: model.addVar(lb=0.0, ub=1.0, vtype=GRB.CONTINUOUS, name=f\"xi_{i}\")\n",
    "        for i in nodes\n",
    "    }\n",
    "\n",
    "    model.update()\n",
    "\n",
    "    # Flow constraints: single path from source to sink\n",
    "    # 1) Source: sum of outgoing arcs is 1\n",
    "    model.addConstr(\n",
    "        gp.quicksum(alpha[(i, j)] for (i, j) in out_arcs[source]) == 1,\n",
    "        name=\"source_flow\",\n",
    "    )\n",
    "\n",
    "    # 2) Sink: sum of incoming arcs is 1\n",
    "    model.addConstr(\n",
    "        gp.quicksum(alpha[(i, j)] for (i, j) in in_arcs[sink]) == 1,\n",
    "        name=\"sink_flow\",\n",
    "    )\n",
    "\n",
    "    # 3) Intermediate nodes: flow conservation\n",
    "    for i in nodes:\n",
    "        if i in (source, sink):\n",
    "            continue\n",
    "        model.addConstr(\n",
    "            gp.quicksum(alpha[(i, j)] for (i, j) in out_arcs[i])\n",
    "            - gp.quicksum(alpha[(u, v)] for (u, v) in in_arcs[i])\n",
    "            == 0,\n",
    "            name=f\"flow_balance_{i}\",\n",
    "        )\n",
    "\n",
    "    # Linking constraints w_ij <= xi_i and w_ij <= alpha_ij\n",
    "    for (i, j) in edges:\n",
    "        model.addConstr(w[(i, j)] <= xi[i], name=f\"w_le_xi_{i}_{j}\")\n",
    "        model.addConstr(w[(i, j)] <= alpha[(i, j)], name=f\"w_le_alpha_{i}_{j}\")\n",
    "\n",
    "    # Budget constraint: sum_i xi_i <= Gamma\n",
    "    model.addConstr(\n",
    "        gp.quicksum(xi[i] for i in nodes) <= Gamma,\n",
    "        name=\"budget_Gamma\",\n",
    "    )\n",
    "\n",
    "    # Objective: sum_(i,j) bar_p[i] * alpha_ij + hat_p[i] * w_ij\n",
    "    obj_expr = gp.LinExpr()\n",
    "    for (i, j) in edges:\n",
    "        if 0 <= i < n:\n",
    "            obj_expr += bar_p[i] * alpha[(i, j)] + hat_p[i] * w[(i, j)]\n",
    "\n",
    "    model.setObjective(obj_expr, GRB.MAXIMIZE)\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status != GRB.OPTIMAL:\n",
    "        raise RuntimeError(\n",
    "            f\"Gurobi did not find an optimal solution. Status: {model.status}\"\n",
    "        )\n",
    "\n",
    "    value = model.ObjVal\n",
    "    alpha_sol = {e: alpha[e].X for e in edges}\n",
    "    xi_sol = {i: xi[i].X for i in nodes}\n",
    "    w_sol = {e: w[e].X for e in edges}\n",
    "\n",
    "    path_arcs = _extract_path_from_binary_flow(alpha_sol, out_arcs, source, sink)\n",
    "\n",
    "    return {\n",
    "        \"value\": value,\n",
    "        \"path_arcs\": path_arcs,\n",
    "        \"alpha\": alpha_sol,\n",
    "        \"xi\": xi_sol,\n",
    "        \"w\": w_sol,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51d009e-23af-43c3-ae96-ef6fb4dc8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_graph(edges):\n",
    "    nodes = set()\n",
    "    for i,j in edges:\n",
    "        nodes.add(i); nodes.add(j)\n",
    "    out_arcs = {i: [] for i in nodes}\n",
    "    in_arcs  = {i: [] for i in nodes}\n",
    "    for (i,j) in edges:\n",
    "        out_arcs[i].append((i,j))\n",
    "        in_arcs[j].append((i,j))\n",
    "    return nodes, out_arcs, in_arcs\n",
    "\n",
    "def _extract_path_from_binary_flow(alpha_sol, out_arcs, source, sink):\n",
    "    path = []\n",
    "    cur = source\n",
    "    visited = set()\n",
    "    while cur != sink and cur not in visited:\n",
    "        visited.add(cur)\n",
    "        nxt = None\n",
    "        for e in out_arcs[cur]:\n",
    "            if alpha_sol[e] > 0.5:\n",
    "                nxt = e\n",
    "                break\n",
    "        if nxt is None:\n",
    "            break\n",
    "        path.append(nxt)\n",
    "        cur = nxt[1]\n",
    "    return path\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4759319-d1d4-4458-b317-6091f3b03bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from gurobipy import GRB\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) read psplib single-mode .sm\n",
    "# ============================================================\n",
    "\n",
    "def _ints(tokens):\n",
    "    return [int(x) for x in tokens]\n",
    "\n",
    "def _index_of_line(lines, substr):\n",
    "    for i, ln in enumerate(lines):\n",
    "        if substr in ln:\n",
    "            return i\n",
    "    raise ValueError(substr)\n",
    "\n",
    "def _rhs(line):\n",
    "    return line.split(\":\",1)[1].strip()\n",
    "\n",
    "def parse_psplib_sm(path):\n",
    "    path = Path(path)\n",
    "    with path.open() as f:\n",
    "        lines = [ln.rstrip() for ln in f]\n",
    "\n",
    "    nj = int(_rhs(lines[_index_of_line(lines,\"jobs (incl. supersource\")]))\n",
    "    nr = int(_rhs(lines[_index_of_line(lines,\"- renewable\")]).split()[0])\n",
    "\n",
    "    prec_off = _index_of_line(lines,\"PRECEDENCE RELATIONS:\")+2\n",
    "    attr_off = _index_of_line(lines,\"REQUESTS/DURATIONS\")+3\n",
    "    cap_off  = _index_of_line(lines,\"RESOURCEAVAILABILITIES\")+2\n",
    "\n",
    "    jobs = [f\"j{i+1}\" for i in range(nj)]\n",
    "    resources=[f\"r{k+1}\" for k in range(nr)]\n",
    "\n",
    "    succs={}\n",
    "    for ix,j in enumerate(jobs):\n",
    "        toks = lines[prec_off+ix].split()\n",
    "        succs[j]=[f\"j{int(s)}\" for s in toks[3:]]\n",
    "\n",
    "    durations={}\n",
    "    demands={}\n",
    "    for ix,j in enumerate(jobs):\n",
    "        toks=lines[attr_off+ix].split()\n",
    "        durations[j]=int(toks[2])\n",
    "        rd=_ints(toks[3:])\n",
    "        for kk,res in enumerate(resources):\n",
    "            demands[(j,res)]=rd[kk]\n",
    "\n",
    "    cap_tokens=lines[cap_off].split()\n",
    "    capacities={resources[k]:int(cap_tokens[k]) for k in range(nr)}\n",
    "\n",
    "    return dict(\n",
    "        jobs=jobs,\n",
    "        resources=resources,\n",
    "        succs=succs,\n",
    "        durations=durations,\n",
    "        demands=demands,\n",
    "        capacities=capacities\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) convert to robust RCPSP sets\n",
    "# ============================================================\n",
    "\n",
    "def psplib_to_rcpsp_sets(data):\n",
    "    jobs=data[\"jobs\"]\n",
    "    resources=data[\"resources\"]\n",
    "    succs=data[\"succs\"]\n",
    "    durations=data[\"durations\"]\n",
    "    demands=data[\"demands\"]\n",
    "    caps=data[\"capacities\"]\n",
    "\n",
    "    job_index={j:i for i,j in enumerate(jobs)}\n",
    "    V=list(job_index.values())\n",
    "\n",
    "    E=[]\n",
    "    for jf,scl in succs.items():\n",
    "        i=job_index[jf]\n",
    "        for jt in scl:\n",
    "            E.append((i,job_index[jt]))\n",
    "\n",
    "    K=resources[:]\n",
    "\n",
    "    bar_p={job_index[j]:durations[j] for j in jobs}\n",
    "    hat_p={i:bar_p[i]/2.0 for i in V}\n",
    "\n",
    "    r={}\n",
    "    for j in jobs:\n",
    "        i=job_index[j]\n",
    "        for res in resources:\n",
    "            r[i,res]=demands[(j,res)]\n",
    "\n",
    "    Nk={res:caps[res] for res in resources}\n",
    "\n",
    "    return V,E,K,bar_p,hat_p,r,Nk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) batch benchmark over folder\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gurobipy import GRB\n",
    "\n",
    "\n",
    "def _extract_best_value(res, solver_name=\"\"):\n",
    "    \"\"\"\n",
    "    Try to extract an objective value from the result object `res`,\n",
    "    regardless of its exact structure.\n",
    "    \"\"\"\n",
    "    # If it's a dict, try common keys\n",
    "    if isinstance(res, dict):\n",
    "        for key in [\"best_value\", \"rho\", \"obj\", \"objective\", \"value\"]:\n",
    "            if key in res:\n",
    "                return res[key]\n",
    "\n",
    "    # If it's a Gurobi model\n",
    "    try:\n",
    "        if hasattr(res, \"ObjVal\"):\n",
    "            return res.ObjVal\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # If all failed, return NaN\n",
    "    print(f\"[WARN] Could not extract objective for solver='{solver_name}'.\")\n",
    "    return float(\"nan\")\n",
    "\n",
    "\n",
    "def benchmark(folder, gammas=(3, 5, 5.5, 7)):\n",
    "    rows = []\n",
    "    files = [f for f in os.listdir(folder) if f.endswith(\".sm\")]\n",
    "\n",
    "    for fn in files:\n",
    "        full = os.path.join(folder, fn)\n",
    "        data = parse_psplib_sm(full)\n",
    "        V, E, K, bar_p, hat_p, r, Nk = psplib_to_rcpsp_sets(data)\n",
    "\n",
    "        n = len(V)\n",
    "        edges = E\n",
    "        source = min(V)\n",
    "        sink = max(V)\n",
    "\n",
    "        bar = [bar_p[i] for i in range(n)]\n",
    "        hat = [hat_p[i] for i in range(n)]\n",
    "\n",
    "        for Gamma in gammas:\n",
    "            # SHIMRITS\n",
    "            t0 = time.perf_counter()\n",
    "            res1 = solve_SHIMRITS_adversary(\n",
    "                bar_p=bar,\n",
    "                hat_p=hat,\n",
    "                edges=edges,\n",
    "                source=source,\n",
    "                sink=sink,\n",
    "                Gamma=Gamma,\n",
    "                gurobi_output=False,\n",
    "            )\n",
    "            t1 = time.perf_counter() - t0\n",
    "\n",
    "            rows.append(\n",
    "                dict(\n",
    "                    dataset=os.path.basename(folder),\n",
    "                    n=n,\n",
    "                    file=fn,\n",
    "                    Gamma=Gamma,\n",
    "                    solver=\"SHIMRITS\",\n",
    "                    runtime=t1,\n",
    "                    val=res1[\"best_value\"],\n",
    "                    path_arcs=res1.get(\"path_arcs\"),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # BRUNI\n",
    "            t0 = time.perf_counter()\n",
    "            res2 = solve_adversary_bruni(\n",
    "                bar_p=bar,\n",
    "                hat_p=hat,\n",
    "                edges=edges,\n",
    "                source=source,\n",
    "                sink=sink,\n",
    "                Gamma=Gamma,\n",
    "                gurobi_output=False,\n",
    "            )\n",
    "            t2 = time.perf_counter() - t0\n",
    "\n",
    "            rows.append(\n",
    "                dict(\n",
    "                    dataset=os.path.basename(folder),\n",
    "                    n=n,\n",
    "                    file=fn,\n",
    "                    Gamma=Gamma,\n",
    "                    solver=\"bruni\",\n",
    "                    runtime=t2,\n",
    "                    val=res2[\"value\"],\n",
    "                    path_arcs=res2.get(\"path_arcs\"),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7c2cb0-1fe2-4715-bffe-6af4b92a5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running benchmark for folder: js30path\n",
      "Gammas: (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "Wrote results to: results_js30path.txt\n",
      "[OK] Finished folder: js30path\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running benchmark for folder: js60path\n",
      "Gammas: (2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30)\n",
      "Wrote results to: results_js60path.txt\n",
      "[OK] Finished folder: js60path\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running benchmark for folder: js90path\n",
      "Gammas: (3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45)\n",
      "Wrote results to: results_js90path.txt\n",
      "[OK] Finished folder: js90path\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def write_results_txt(df, out_path, default_dataset=None):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add dataset if missing\n",
    "    if \"dataset\" not in df.columns:\n",
    "        df[\"dataset\"] = default_dataset if default_dataset is not None else \"NA\"\n",
    "\n",
    "    # Optional columns that might be missing\n",
    "    if \"n\" not in df.columns:\n",
    "        df[\"n\"] = \"NA\"\n",
    "    if \"path_arcs\" not in df.columns:\n",
    "        df[\"path_arcs\"] = None\n",
    "\n",
    "    # Sort only by columns that exist\n",
    "    sort_cols = [c for c in [\"dataset\", \"file\", \"Gamma\", \"solver\"] if c in df.columns]\n",
    "    if sort_cols:\n",
    "        df = df.sort_values(sort_cols).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Adversary benchmark results\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            dataset = row.get(\"dataset\", \"NA\")\n",
    "            file_ = row.get(\"file\", \"NA\")\n",
    "            n = row.get(\"n\", \"NA\")\n",
    "            Gamma = row.get(\"Gamma\", \"NA\")\n",
    "            solver = row.get(\"solver\", \"NA\")\n",
    "            runtime = row.get(\"runtime\", float(\"nan\"))\n",
    "            val = row.get(\"val\", float(\"nan\"))\n",
    "\n",
    "            f.write(\n",
    "                f\"dataset={dataset} | file={file_} | n={n} | \"\n",
    "                f\"Gamma={Gamma} | solver={solver} | \"\n",
    "                f\"runtime={runtime:.6f}s | val={val}\\n\"\n",
    "            )\n",
    "\n",
    "            path = row.get(\"path_arcs\", None)\n",
    "            if isinstance(path, list):\n",
    "                f.write(f\"optimal_path_length={len(path)}\\n\")\n",
    "                f.write(f\"optimal_path_arcs={path}\\n\")\n",
    "            else:\n",
    "                f.write(\"optimal_path_arcs=None\\n\")\n",
    "\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    print(f\"Wrote results to: {out_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''if __name__ == \"__main__\":\n",
    "    GAMMAS_BY_FOLDER = {\n",
    "        \"js30path\": tuple(range(1, 16)),      # 1..15\n",
    "        \"js60path\": tuple(range(2, 31, 2)),   # 2,4,...,30\n",
    "        \"js90path\": tuple(range(3, 46, 3)),   # 3,6,...,45\n",
    "    }\n",
    "\n",
    "    folders = [\"js30path\", \"js60path\", \"js90path\"]\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"[WARN] folder not found, skipping: {folder}\")\n",
    "            continue\n",
    "\n",
    "        gammas = GAMMAS_BY_FOLDER.get(folder)\n",
    "        if gammas is None:\n",
    "            print(f\"[WARN] no Gamma definition for folder: {folder}, skipping\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Running benchmark for folder: {folder}\")\n",
    "        print(f\"Gammas: {gammas}\")\n",
    "\n",
    "        df = benchmark(folder, gammas=gammas)\n",
    "        print(df)\n",
    "\n",
    "        # 1) write txt first (includes optimal chosen path)\n",
    "        out_txt = f\"results_{folder}.txt\"\n",
    "        write_results_txt(df, out_path=out_txt)\n",
    "\n",
    "        # 2) plots\n",
    "        plot_box_per_folder(df, folder)\n",
    "        plot_bar_mean_per_folder(df, folder)'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    GAMMAS_BY_FOLDER = {\n",
    "        \"js30path\": tuple(range(1, 16)),      # 1..15\n",
    "        \"js60path\": tuple(range(2, 31, 2)),   # 2,4,...,30\n",
    "        \"js90path\": tuple(range(3, 46, 3)),   # 3,6,...,45\n",
    "    }\n",
    "\n",
    "    folders = [\"js30path\", \"js60path\", \"js90path\"]\n",
    "\n",
    "    all_results = {}   # keep dfs in memory for later plotting if wanted\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"[WARN] folder not found, skipping: {folder}\")\n",
    "            continue\n",
    "\n",
    "        gammas = GAMMAS_BY_FOLDER.get(folder)\n",
    "        if gammas is None:\n",
    "            print(f\"[WARN] no Gamma definition for folder: {folder}, skipping\")\n",
    "            continue\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Running benchmark for folder: {folder}\")\n",
    "        print(f\"Gammas: {gammas}\")\n",
    "\n",
    "        df = benchmark(folder, gammas=gammas)\n",
    "        all_results[folder] = df\n",
    "\n",
    "        # ---- write TXT (includes optimal path arcs) ----\n",
    "        out_txt = f\"results_{folder}.txt\"\n",
    "        write_results_txt(df, out_path=out_txt, default_dataset=folder)\n",
    "\n",
    "        print(f\"[OK] Finished folder: {folder}\")\n",
    "        print(\"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad74165-ae12-488b-890d-f29841cb1123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfef9a3-09e6-4125-ab7f-3683aa342cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c493462-8ada-447e-ada1-409fb1bd0455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dde16-e730-4ef4-80fb-cb6617bcbba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bee2e4-cd99-41d2-ad96-7b099e43a295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc1362-cab3-460f-a071-b7421b0cf398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
